{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "\n",
    "with open('gensim_w2v.txt') as f:\n",
    "    first_line = f.readline().strip()\n",
    "    vsize, dim = map(int,first_line.split(' '))\n",
    "    \n",
    "# vsize=1779969 # for w2v.txt\n",
    "# vsize=829609 # for gensim_w2v.txt\n",
    "\n",
    "\n",
    "def load_embeddings(path):\n",
    "    print('Loading word embeddings...')\n",
    "    words = pd.read_csv(path, sep=\" \", index_col=0, skiprows=[0],\n",
    "                        na_values=None, keep_default_na=False, header=None,\n",
    "                        quoting=csv.QUOTE_NONE,\n",
    "                        encoding='iso-8859-1')\n",
    "    print('Loaded.')\n",
    "    if len(words.columns) == 301:\n",
    "        words=words.drop(columns=[301])\n",
    "    matrix = words.values\n",
    "    index_to_word = list(words[:n_words].index)\n",
    "    word_to_index = {\n",
    "        word: ind for ind, word in enumerate(index_to_word)\n",
    "    }\n",
    "    return matrix, word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "matrix, word_to_index, index_to_word = load_embeddings(\"gensim_w2v.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index[\"<unknown>\"] = vsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_matrix = torch.tensor(matrix[:vsize])\n",
    "mean_in = torch.mean(in_matrix,0).unsqueeze(0)\n",
    "in_matrix = torch.cat((in_matrix,mean_in))\n",
    "\n",
    "out_matrix = torch.tensor(matrix[vsize:])\n",
    "mean_out = torch.mean(out_matrix,0).unsqueeze(0)\n",
    "out_matrix = torch.cat((out_matrix,mean_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0032, -0.2789, -0.1183,  ..., -0.1143, -0.0386, -0.0409],\n",
       "        [-0.4922, -0.0562,  0.0411,  ..., -0.2282,  0.1516,  0.0028],\n",
       "        [-0.0645, -0.2697,  0.1118,  ...,  0.0509, -0.2716, -0.0535],\n",
       "        ...,\n",
       "        [ 0.0850, -0.0629, -0.2115,  ..., -0.2131,  0.0382, -0.0792],\n",
       "        [ 0.1816, -0.0007, -0.1396,  ..., -0.0863,  0.0404, -0.0868],\n",
       "        [ 0.1386,  0.0686, -0.1444,  ..., -0.1766,  0.0639, -0.0842]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embedding = torch.nn.Embedding(vsize+1, dim)\n",
    "out_embedding = torch.nn.Embedding(vsize+1, dim)\n",
    "in_embedding.weight.data.copy_(in_matrix)\n",
    "out_embedding.weight.data.copy_(out_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class Word2Vec:\n",
    "    \"\"\"\n",
    "    Class for using global word embeddings.\n",
    "    PMI estimated as inner product of\n",
    "    input embedding of w1 with output embedding of w2\n",
    "    \"\"\"\n",
    "    def __init__(self, device, model_spec, path):\n",
    "        self.device = device\n",
    "        with open(path) as f:\n",
    "            first_line = f.readline().strip()\n",
    "            vsize, dim = map(int,first_line.split(' '))\n",
    "        self.vocabsize = vsize\n",
    "        self.embedding_dim = dim\n",
    "        print(f'Loading word embeddings from {path} ...')\n",
    "        matrix, self.word_to_index = self._load_embeddings(path)\n",
    "        self.in_embedding, self.out_embedding = self._prepare_embeddings(matrix)\n",
    "        print('Loaded.')\n",
    "        print(f\"Embedding model '{model_spec}' initialized on {device}.\")\n",
    "\n",
    "    def _load_embeddings(self, path):\n",
    "        words = pd.read_csv(path, sep=\" \", index_col=0, skiprows=[0],\n",
    "                            na_values=None, keep_default_na=False, header=None,\n",
    "                            quoting=csv.QUOTE_NONE,\n",
    "                            encoding='iso-8859-1')\n",
    "        if len(words.columns) == self.embedding_dim+1:\n",
    "            words = words.drop(columns=[self.embedding_dim+1])\n",
    "        matrix = words.values\n",
    "        index_to_word = list(words[:self.vocabsize].index)\n",
    "        word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }\n",
    "        return matrix, word_to_index\n",
    "\n",
    "    def _prepare_embeddings(self, matrix):\n",
    "        # Add on a mean vector embedding for unks\n",
    "        in_matrix = torch.tensor(matrix[:self.vocabsize])\n",
    "        mean_in = torch.mean(in_matrix, 0).unsqueeze(0)\n",
    "        in_matrix = torch.cat((in_matrix, mean_in))\n",
    "        out_matrix = torch.tensor(matrix[self.vocabsize:])\n",
    "        mean_out = torch.mean(out_matrix, 0).unsqueeze(0)\n",
    "        out_matrix = torch.cat((out_matrix, mean_out))\n",
    "\n",
    "        in_embedding = torch.nn.Embedding(\n",
    "            self.vocabsize+1, self.embedding_dim).to(self.device)\n",
    "        out_embedding = torch.nn.Embedding(\n",
    "            self.vocabsize+1, self.embedding_dim).to(self.device)\n",
    "        in_embedding.weight.data.copy_(in_matrix.to(self.device))\n",
    "        out_embedding.weight.data.copy_(out_matrix.to(self.device))\n",
    "        return in_embedding, out_embedding\n",
    "\n",
    "    def _encode(self, ptb_tokenlist):\n",
    "        # word_to_index = self.word_to_index\n",
    "        # word_to_index[\"<unknown>\"] = self.vocabsize\n",
    "        sentence_as_ids = [\n",
    "            self.word_to_index.get(word, self.vocabsize)\n",
    "            for word in ptb_tokenlist]\n",
    "        return sentence_as_ids\n",
    "\n",
    "    def ptb_tokenlist_to_pmi_matrix(\n",
    "            self, ptb_tokenlist, add_special_tokens=True,\n",
    "            pad_left=None, pad_right=None, verbose=True):\n",
    "        \"\"\"Maps tokenlist to PMI matrix,\n",
    "        TODO: this just ignores the rest of the arguments,\n",
    "        but this way no custom call from main.py\"\"\"\n",
    "\n",
    "        sentence_as_ids = self._encode(ptb_tokenlist)\n",
    "        sentence_as_ids = torch.tensor(sentence_as_ids).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            in_sentence = self.in_embedding(sentence_as_ids)\n",
    "            out_sentence = self.out_embedding(sentence_as_ids)\n",
    "            pmi_matrix = torch.matmul(in_sentence, out_sentence.T)\n",
    "        pseudo_loglik = 0  # meaningless for now\n",
    "        return pmi_matrix, pseudo_loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings from gensim_w2v.txt ...\n",
      "Loaded.\n",
      "Embedding model 'w2v' initialized on cpu.\n"
     ]
    }
   ],
   "source": [
    "MODEL=Word2Vec('cpu', 'w2v', 'gensim_w2v.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_tokenlist = [\"queen\",\"king\",\"zoo\",\"zoos\"]\n",
    "\n",
    "pmi_matrix, pseudo_loglik = MODEL.ptb_tokenlist_to_pmi_matrix(\n",
    "    ptb_tokenlist, add_special_tokens=True, verbose=True,\n",
    "    pad_left=None, pad_right=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6373,  0.7513, -0.6049, -0.9455],\n",
       "        [ 0.5922,  0.9947, -0.8691, -1.0358],\n",
       "        [-0.5677, -0.6622,  1.4823,  1.2766],\n",
       "        [-0.8843, -0.7736,  1.0375,  1.9962]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
